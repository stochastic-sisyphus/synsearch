from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np
from typing import List, Dict, Any
from tqdm import tqdm

class EmbeddingGenerator:
    def __init__(self, model_name: str = 'all-mpnet-base-v2', **kwargs):
        """Initialize the embedding generator with a pre-trained model.
        
        Args:
            model_name: Name of the pre-trained model to use (default: 'all-mpnet-base-v2')
            **kwargs: Additional arguments for model configuration
        """
        self.model_name = model_name
        self.model = AutoModel.from_pretrained(model_name)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
    def generate_embeddings(self, texts: List[str], batch_size: int = 32) -> np.ndarray:
        """Generate embeddings for a list of texts.
        
        Args:
            texts: List of texts to generate embeddings for
            batch_size: Size of batches for processing (default: 32)
            
        Returns:
            numpy.ndarray: Array of embeddings
        """
        embeddings = []
        self.model.eval()
        
        with torch.no_grad():
            for i in tqdm(range(0, len(texts), batch_size)):
                batch_texts = texts[i:i + batch_size]
                inputs = self.tokenizer(
                    batch_texts,
                    padding=True,
                    truncation=True,
                    max_length=512,
                    return_tensors="pt"
                ).to(self.device)
                
                outputs = self.model(**inputs)
                # Use [CLS] token embeddings or mean pooling
                batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
                embeddings.extend(batch_embeddings)
                
        return np.array(embeddings)
    
    def get_embedding_dimension(self) -> int:
        """Get the dimension of the embeddings generated by this model."""
        return self.model.config.hidden_size
    
    def __call__(self, texts: List[str], **kwargs) -> np.ndarray:
        """Convenience method to generate embeddings."""
        return self.generate_embeddings(texts, **kwargs)